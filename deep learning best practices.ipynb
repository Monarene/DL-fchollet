{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\Anaconda3.2\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing neccessary libraires\n",
    "import keras\n",
    "from keras import Input, layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "\n",
    "from keras import callbacks\n",
    "#making the dataset\n",
    "x_train = np.random.random((1000,64))\n",
    "y_train = np.random.random((1000,32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "=================================================================\n",
      "Total params: 4,192\n",
      "Trainable params: 4,192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 55.3245 - acc: 0.0290\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 55.2851 - acc: 0.0320\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 55.2732 - acc: 0.0440\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 55.2667 - acc: 0.0460\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 55.2626 - acc: 0.0490\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 55.2593 - acc: 0.0540\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 55.2560 - acc: 0.0480\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 55.2537 - acc: 0.0530\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 55.2510 - acc: 0.0530\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 55.2485 - acc: 0.0560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eccc64f978>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#building the model using keras functional API\n",
    "input_tensor = Input(shape=(64,))\n",
    "layer1 = layers.Dense(32, activation='relu')(input_tensor)\n",
    "layer2 = layers.Dense(32, activation='relu')(layer1)\n",
    "output_tensor = layers.Dense(32, activation='softmax')(layer2)\n",
    "model = Model(input_tensor, output_tensor)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 10000)  640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, None, 500)    16000       question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 32)           1284224     embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 16)           33088       embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 48)           0           lstm_5[0][0]                     \n",
      "                                                                 lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 500)          24500       concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,997,812\n",
      "Trainable params: 1,997,812\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#building an awesome multi-input model\n",
    "text_size_vocab = 10000\n",
    "question_size_vocab = 500\n",
    "answer_size_vocab = 500\n",
    "\n",
    "text_input = Input((None,), dtype='int32', name='text')\n",
    "embedding_layer = layers.Embedding(64, text_size_vocab)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedding_layer)\n",
    "\n",
    "question_input = Input((None,), dtype='int32',name ='question')\n",
    "embedded_question = layers.Embedding(32, question_size_vocab)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis =-1)\n",
    "answers = layers.Dense(answer_size_vocab, activation='softmax')(concatenated)\n",
    "\n",
    "model_2 = Model([text_input, question_input], answers)\n",
    "model_2.compile('rmsprop',loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "\n",
    "model_2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[56,1] = 238 is not in [0, 32)\n\t [[Node: embedding_4/embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@training_2/RMSprop/Assign_3\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_4/embeddings/read, _arg_question_1_0_1, training_2/RMSprop/gradients/embedding_4/embedding_lookup_grad/concat/axis)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8381d7fe2fc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mquestions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion_size_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0manswers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswer_size_vocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3.2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3.2\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n\u001b[1;32m-> 1454\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.2\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: indices[56,1] = 238 is not in [0, 32)\n\t [[Node: embedding_4/embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@training_2/RMSprop/Assign_3\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_4/embeddings/read, _arg_question_1_0_1, training_2/RMSprop/gradients/embedding_4/embedding_lookup_grad/concat/axis)]]"
     ]
    }
   ],
   "source": [
    "samples = 1000\n",
    "max_features =10\n",
    "text= np.random.randint(1, text_size_vocab, size = (samples, max_features))\n",
    "questions = np.random.randint(1, question_size_vocab, size = (samples, max_features))\n",
    "answers = np.random.randint(0,1,size=(samples, answer_size_vocab))\n",
    "model_2.fit([text, questions], answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 5000\n",
    "num_income_groups = 10\n",
    "posts_input = Input(shape=(None,),name='posts')\n",
    "embedding_posts = layers.Embedding(256,vocabulary_size)(posts_input)\n",
    "x = layers.Conv1D(128,5,activation='relu')(embedding_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256,5,activation='relu')(x)\n",
    "x = layers.Conv1D(256,5,activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256,5,activation='relu')(x)\n",
    "x = layers.Conv1D(256,5,activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128,activation='relu')(x)\n",
    "\n",
    "#now the layers that would have to be produced from the main architecture\n",
    "age_predictions = layers.Dense(1,name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups,activation='softmax',name='income')(x)\n",
    "gender = layers.Dense(2,activation='softmax',name='gender')(x)\n",
    "\n",
    "model_3 = Model(posts_input, [age_predictions, income_prediction, gender])\n",
    "model_3.compile(optimizer='rmsprop',loss={'age':'mse',\n",
    "                                          'income':'categorical_crossentropy',\n",
    "                                         'gender':'binary_crossentropy'},\n",
    "                loss_weights={'age':0.25,'income':1.0,'gender':0.1})\n",
    "\n",
    "#I didnt run the fit part because this part was only to foster learning\n",
    "model_3.fit(posts, [age_targets, income_targets, gender_targets], \n",
    "            epochs = 10,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 5000)   1280000     posts[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, None, 128)    3200128     embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, None, 128)    0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, None, 256)    164096      max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, None, 256)    327936      conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, None, 256)    0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, None, 256)    327936      max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, None, 256)    327936      conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 256)          0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            129         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 10)           1290        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 2)            258         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,662,605\n",
      "Trainable params: 5,662,605\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time to write the Xception model\n",
    "# It is so beautiful\n",
    "inputer = Input((None,None,3), name='pictures')\n",
    "branch_a = layers.Conv2D(128,1,activation='relu',strides=2)(inputer)\n",
    "branch_b = layers.Conv2D(128,1,activation='relu')(inputer)\n",
    "branch_b = layers.Conv2D(128,3,activation='relu', strides=2)(branch_b)\n",
    "branch_c = layers.AvgPool2D((3,3),strides=2)(inputer)\n",
    "branch_c = layers.Conv2D(128,3,activation='relu')(branch_c)\n",
    "branch_d = layers.Conv2D(128,1,activation='relu')(inputer)\n",
    "branch_d = layers.Conv2D(128,3,activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128,3,activation='relu',strides=2)(branch_d)\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)\n",
    "final_layer = layers.Dense(num_classes,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\Anaconda3.2\\lib\\site-packages\\keras\\engine\\network.py:186: UserWarning: Model inputs must come from `keras.layers.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to your model was not an Input tensor, it was generated by layer lstm_3.\n",
      "Note that input tensors are instantiated via `tensor = keras.layers.Input(shape)`.\n",
      "The tensor that caused the issue was: lstm_3/TensorArrayReadV3:0\n",
      "  str(x.name))\n",
      "C:\\Users\\Michael\\Anaconda3.2\\lib\\site-packages\\keras\\engine\\network.py:186: UserWarning: Model inputs must come from `keras.layers.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to your model was not an Input tensor, it was generated by layer lstm_3.\n",
      "Note that input tensors are instantiated via `tensor = keras.layers.Input(shape)`.\n",
      "The tensor that caused the issue was: lstm_3_1/TensorArrayReadV3:0\n",
      "  str(x.name))\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-015c21a5c574>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mfinal_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmodel_4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mleft_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfinal_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3.2\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.2\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[0;32m     92\u001b[0m             \u001b[1;31m# Graph network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;31m# Subclassed network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.2\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;31m# It's supposed to be an input layer, so only one node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;31m# and one tensor output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[0mnode_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#learning how to instantiate\n",
    "lstm = layers.LSTM(32)\n",
    "\n",
    "left_input = Input((None,128), name='left_input')\n",
    "left_input = lstm(left_input)\n",
    "\n",
    "right_input = Input((None, 128), name='right_input')\n",
    "right_input = lstm(right_input)\n",
    "\n",
    "merged = layers.concatenate([left_input, right_input], axis = -1)\n",
    "final_output = layers.Dense(1,activation='sigmoid')(merged)\n",
    "\n",
    "model_4 = Model([left_input, right_input],final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception = keras.applications.Xception(include_top=False, weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\Anaconda3.2\\lib\\site-packages\\keras\\engine\\network.py:186: UserWarning: Model inputs must come from `keras.layers.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to your model was not an Input tensor, it was generated by layer xception.\n",
      "Note that input tensors are instantiated via `tensor = keras.layers.Input(shape)`.\n",
      "The tensor that caused the issue was: xception/block14_sepconv2_act/Relu:0\n",
      "  str(x.name))\n",
      "C:\\Users\\Michael\\Anaconda3.2\\lib\\site-packages\\keras\\engine\\network.py:186: UserWarning: Model inputs must come from `keras.layers.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to your model was not an Input tensor, it was generated by layer xception.\n",
      "Note that input tensors are instantiated via `tensor = keras.layers.Input(shape)`.\n",
      "The tensor that caused the issue was: xception_1/block14_sepconv2_act/Relu:0\n",
      "  str(x.name))\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-8256f89d4e99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mleft_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3.2\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.2\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[0;32m     92\u001b[0m             \u001b[1;31m# Graph network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;31m# Subclassed network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.2\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;31m# It's supposed to be an input layer, so only one node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;31m# and one tensor output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[0mnode_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "left_input = Input((250,250,3))\n",
    "left_input = xception(left_input)\n",
    "\n",
    "right_input = Input((250,250,3))\n",
    "right_input = xception(right_input)\n",
    "merged = layers.concatenate([left_input, right_input], axis=-1)\n",
    "predictions = layers.Dense(1,activation='sigmoid')(merged)\n",
    "\n",
    "model = Model([left_input, right_input], predictions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(n_samples = 10000,n_features = 12,n_classes = 2,weights=[0.6,0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27084756, -1.24426784, -0.6076227 , ..., -0.06653174,\n",
       "         0.37344524, -0.2708249 ],\n",
       "       [-0.58553508, -0.97572658, -1.11194589, ..., -0.67305139,\n",
       "        -0.73403452,  1.07075999],\n",
       "       [-0.34155723, -1.31244953,  1.76793729, ...,  2.65666615,\n",
       "        -0.80062065,  0.47199139],\n",
       "       ...,\n",
       "       [ 1.46732578, -0.74649137, -1.09923854, ..., -0.62160874,\n",
       "         0.27439605, -0.04659363],\n",
       "       [-1.79661379, -0.56753839, -1.30200986, ...,  0.83147013,\n",
       "        -1.55602165,  2.02348696],\n",
       "       [-0.25134378, -0.21830916, -1.17936375, ..., -0.01702641,\n",
       "         1.26344088, -1.12085153]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [callbacks.EarlyStopping(patience=3,monitor='val_acc'),\n",
    "                callbacks.ModelCheckpoint('model_5.h5',monitor='val_loss',save_best_only=True)]\n",
    "callback_list_2 = [callbacks.ReduceLROnPlateau(monitor='val_acc',factor = 0.1,patience=5,verbose=1, min_lr=0.0001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/50\n",
      "7500/7500 [==============================] - 4s 540us/step - loss: 0.5800 - acc: 0.7093 - val_loss: 0.4787 - val_acc: 0.8396\n",
      "Epoch 2/50\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.3547 - acc: 0.8855 - val_loss: 0.2725 - val_acc: 0.9020\n",
      "Epoch 3/50\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.2428 - acc: 0.9115 - val_loss: 0.2415 - val_acc: 0.9172\n",
      "Epoch 4/50\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.2269 - acc: 0.9141 - val_loss: 0.2344 - val_acc: 0.9184\n",
      "Epoch 5/50\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.2209 - acc: 0.9176 - val_loss: 0.2297 - val_acc: 0.9196\n",
      "Epoch 6/50\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.2152 - acc: 0.9203 - val_loss: 0.2252 - val_acc: 0.9188\n",
      "Epoch 7/50\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.2111 - acc: 0.9221 - val_loss: 0.2226 - val_acc: 0.9184\n",
      "Epoch 8/50\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 0.2084 - acc: 0.9237 - val_loss: 0.2197 - val_acc: 0.9212\n",
      "Epoch 9/50\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.2058 - acc: 0.9255 - val_loss: 0.2179 - val_acc: 0.9236\n",
      "Epoch 10/50\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.2039 - acc: 0.9256 - val_loss: 0.2165 - val_acc: 0.9220\n",
      "Epoch 11/50\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.2017 - acc: 0.9265 - val_loss: 0.2167 - val_acc: 0.9244\n",
      "Epoch 12/50\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.2006 - acc: 0.9269 - val_loss: 0.2150 - val_acc: 0.9240\n",
      "Epoch 13/50\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.1993 - acc: 0.9269 - val_loss: 0.2143 - val_acc: 0.9228\n",
      "Epoch 14/50\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.1980 - acc: 0.9279 - val_loss: 0.2127 - val_acc: 0.9244\n"
     ]
    }
   ],
   "source": [
    "the_inputer = Input(shape=(12,))\n",
    "layer_1 = layers.Dense(16,activation='relu')(the_inputer)\n",
    "layer_2 = layers.Dense(16, activation='relu')(layer_1)\n",
    "layer_3 = layers.Dense(16, activation='relu')(layer_2)\n",
    "final_layer = layers.Dense(1,activation='sigmoid')(layer_3)\n",
    "\n",
    "model_5 = Model(the_inputer, final_layer)\n",
    "model_5.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model_5_history = model_5.fit(x_train, y_train,batch_size=128,epochs=50,callbacks=callback_list,validation_data=[x_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 16)                208       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 769\n",
      "Trainable params: 769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/50\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.1972 - acc: 0.9288 - val_loss: 0.2133 - val_acc: 0.9236\n",
      "Epoch 2/50\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.1963 - acc: 0.9287 - val_loss: 0.2134 - val_acc: 0.9236\n",
      "Epoch 3/50\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.1954 - acc: 0.9300 - val_loss: 0.2117 - val_acc: 0.9256\n",
      "Epoch 4/50\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.1946 - acc: 0.9300 - val_loss: 0.2109 - val_acc: 0.9260\n",
      "Epoch 5/50\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.1942 - acc: 0.9305 - val_loss: 0.2107 - val_acc: 0.9260\n",
      "Epoch 6/50\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.1931 - acc: 0.9319 - val_loss: 0.2097 - val_acc: 0.9264\n",
      "Epoch 7/50\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.1920 - acc: 0.9324 - val_loss: 0.2110 - val_acc: 0.9272\n",
      "Epoch 8/50\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.1913 - acc: 0.9315 - val_loss: 0.2099 - val_acc: 0.9264\n",
      "Epoch 9/50\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.1905 - acc: 0.9321 - val_loss: 0.2099 - val_acc: 0.9272\n",
      "Epoch 10/50\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.1900 - acc: 0.9321 - val_loss: 0.2081 - val_acc: 0.9268\n",
      "Epoch 11/50\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.1893 - acc: 0.9333 - val_loss: 0.2090 - val_acc: 0.9276\n",
      "Epoch 12/50\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.1889 - acc: 0.9331 - val_loss: 0.2084 - val_acc: 0.9276\n",
      "Epoch 13/50\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 0.1882 - acc: 0.9327 - val_loss: 0.2074 - val_acc: 0.9272\n",
      "Epoch 14/50\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.1877 - acc: 0.9337 - val_loss: 0.2078 - val_acc: 0.9268\n",
      "Epoch 15/50\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 0.1863 - acc: 0.9341 - val_loss: 0.2077 - val_acc: 0.9284\n",
      "Epoch 16/50\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 0.1860 - acc: 0.9356 - val_loss: 0.2071 - val_acc: 0.9280\n",
      "Epoch 17/50\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.1858 - acc: 0.9341 - val_loss: 0.2063 - val_acc: 0.9284\n",
      "Epoch 18/50\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.1847 - acc: 0.9347 - val_loss: 0.2076 - val_acc: 0.9272\n",
      "Epoch 19/50\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.1843 - acc: 0.9337 - val_loss: 0.2052 - val_acc: 0.9292\n",
      "Epoch 20/50\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 0.1836 - acc: 0.9356 - val_loss: 0.2055 - val_acc: 0.9292\n",
      "Epoch 21/50\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.1829 - acc: 0.9360 - val_loss: 0.2067 - val_acc: 0.9284\n",
      "Epoch 22/50\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.1832 - acc: 0.9357 - val_loss: 0.2063 - val_acc: 0.9300\n",
      "Epoch 23/50\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.1824 - acc: 0.9359 - val_loss: 0.2069 - val_acc: 0.9296\n",
      "Epoch 24/50\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.1821 - acc: 0.9363 - val_loss: 0.2052 - val_acc: 0.9296\n",
      "Epoch 25/50\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.1811 - acc: 0.9360 - val_loss: 0.2048 - val_acc: 0.9300\n",
      "Epoch 26/50\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.1807 - acc: 0.9355 - val_loss: 0.2045 - val_acc: 0.9308\n",
      "Epoch 27/50\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.1799 - acc: 0.9372 - val_loss: 0.2049 - val_acc: 0.9308\n",
      "Epoch 28/50\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.1797 - acc: 0.9364 - val_loss: 0.2043 - val_acc: 0.9308\n",
      "Epoch 29/50\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.1793 - acc: 0.9371 - val_loss: 0.2043 - val_acc: 0.9312\n",
      "Epoch 30/50\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.1789 - acc: 0.9367 - val_loss: 0.2037 - val_acc: 0.9312\n",
      "Epoch 31/50\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.1783 - acc: 0.9379 - val_loss: 0.2037 - val_acc: 0.9312\n",
      "Epoch 32/50\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.1777 - acc: 0.9380 - val_loss: 0.2059 - val_acc: 0.9320\n",
      "Epoch 33/50\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.1779 - acc: 0.9387 - val_loss: 0.2045 - val_acc: 0.9300\n",
      "Epoch 34/50\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.1770 - acc: 0.9372 - val_loss: 0.2051 - val_acc: 0.9312\n",
      "Epoch 35/50\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.1769 - acc: 0.9383 - val_loss: 0.2023 - val_acc: 0.9320\n",
      "Epoch 36/50\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.1763 - acc: 0.9376 - val_loss: 0.2035 - val_acc: 0.9308\n",
      "Epoch 37/50\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.1761 - acc: 0.9391 - val_loss: 0.2039 - val_acc: 0.9320\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 38/50\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.1738 - acc: 0.9391 - val_loss: 0.2030 - val_acc: 0.9316\n",
      "Epoch 39/50\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 0.1735 - acc: 0.9385 - val_loss: 0.2031 - val_acc: 0.9312\n",
      "Epoch 40/50\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.1735 - acc: 0.9381 - val_loss: 0.2032 - val_acc: 0.9312\n",
      "Epoch 41/50\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.1735 - acc: 0.9385 - val_loss: 0.2031 - val_acc: 0.9304\n",
      "Epoch 42/50\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.1734 - acc: 0.9392 - val_loss: 0.2028 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 43/50\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.1734 - acc: 0.9381 - val_loss: 0.2029 - val_acc: 0.9308\n",
      "Epoch 44/50\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.1733 - acc: 0.9384 - val_loss: 0.2029 - val_acc: 0.9304\n",
      "Epoch 45/50\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 0.1733 - acc: 0.9389 - val_loss: 0.2029 - val_acc: 0.9308\n",
      "Epoch 46/50\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 0.1732 - acc: 0.9387 - val_loss: 0.2028 - val_acc: 0.9304\n",
      "Epoch 47/50\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 0.1732 - acc: 0.9385 - val_loss: 0.2027 - val_acc: 0.9304\n",
      "Epoch 48/50\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.1731 - acc: 0.9388 - val_loss: 0.2028 - val_acc: 0.9304\n",
      "Epoch 49/50\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 0.1731 - acc: 0.9388 - val_loss: 0.2027 - val_acc: 0.9304\n",
      "Epoch 50/50\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.1731 - acc: 0.9389 - val_loss: 0.2028 - val_acc: 0.9304\n"
     ]
    }
   ],
   "source": [
    "model_5_fit_2 = model_5.fit(x_train, y_train,batch_size=128,epochs=50,callbacks=callback_list_2,validation_data=[x_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working on sentiment analyisis with the imbd dataset \n",
    "max_features = 2000 # the num of words to take as max features\n",
    "max_len = 500 #maximun number of length of words\n",
    "(train_data, train_target),(test_data, test_target) = imdb.load_data(num_words=max_features,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sequence.pad_sequences(train_data, maxlen=500)\n",
    "test_data = sequence.pad_sequences(test_data, maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.add(layers.Embedding(max_features,128,input_length=max_len,name='embed'))\n",
    "model_6.add(layers.Conv1D(32,7,activation='relu'))\n",
    "model_6.add(layers.MaxPooling1D(5))\n",
    "model_6.add(layers.Conv1D(32,7,activation='relu'))\n",
    "model_6.add(layers.GlobalAveragePooling1D())\n",
    "model_6.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   19,  178,   32],\n",
       "       [   0,    0,    0, ...,   16,  145,   95],\n",
       "       [   0,    0,    0, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   28, 1816,   98],\n",
       "       [   0,    0,    0, ...,  158,   10,   10],\n",
       "       [   0,    0,    0, ...,  220,  484,  867]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18750 samples, validate on 6250 samples\n",
      "Epoch 1/40\n"
     ]
    }
   ],
   "source": [
    "callback_list_3 = [callbacks.TensorBoard(log_dir='tensorboard_dir',histogram_freq=1,\n",
    "                                         embeddings_freq=1,embeddings_data=train_data),\n",
    "                   callbacks.EarlyStopping(patience=3,monitor='val_acc'),\n",
    "                callbacks.ModelCheckpoint('model_6.h5',monitor='val_loss',save_best_only=True)]\n",
    "model_6.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model_6.fit(train_data, train_target,batch_size=32,epochs=40,callbacks = callback_list_3,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing neural architechtures with depthwise seperable convolutional nets\n",
    "Inputer_guy = Input((64,64,3))\n",
    "\n",
    "layer_1 = layers.SeparableConv2D(32,3,activation='relu')(Inputer_guy)\n",
    "layer_2 = layers.SeparableConv2D(64,3,activation='relu')(layer_1)\n",
    "layer_3 = layers.MaxPooling2D(2)(layer_2)\n",
    "\n",
    "layer_4 = layers.SeparableConv2D(64,3,activation='relu')(layer_3)\n",
    "layer_5 = layers.SeparableConv2D(128,3,activation='relu')(layer_4)\n",
    "layer_6 = layers.MaxPooling2D(2)(layer_5)\n",
    "\n",
    "layer_7 = layers.SeparableConv2D(64,3,activation='relu')(layer_6)\n",
    "layer_8 = layers.SeparableConv2D(128,3,activation='relu')(layer_7)\n",
    "layer_9 = layers.GlobalAveragePooling2D()(layer_8)\n",
    "\n",
    "layer_10 = layers.Dense(32,activation='relu')(layer_9)\n",
    "final_layer = layers.Dense(10,activation='softmax')(layer_10)\n",
    "\n",
    "model_7 = Model(Inputer_guy, final_layer)\n",
    "model_7.compile(optimizer='adam',loss='categorical_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_7 (Separabl (None, 62, 62, 32)        155       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_8 (Separabl (None, 60, 60, 64)        2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_9 (Separabl (None, 28, 28, 64)        4736      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_10 (Separab (None, 26, 26, 128)       8896      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_11 (Separab (None, 11, 11, 64)        9408      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_12 (Separab (None, 9, 9, 128)         8896      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 38,949\n",
      "Trainable params: 38,949\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
